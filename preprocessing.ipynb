{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "from utility import Dataset\n",
    "\n",
    "columns = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
    "           'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted',\n",
    "           'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
    "           'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
    "           'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "           'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "           'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
    "           'dst_host_srv_rerror_rate', 'label', 'score']\n",
    "\n",
    "nominal_features = ['protocol_type', 'service', 'flag']\n",
    "binary_features = ['land', 'logged_in', 'root_shell', 'su_attempted', 'is_host_login', 'is_guest_login']\n",
    "numeric_features = [feature for feature in columns if feature not in nominal_features + binary_features + ['label', 'score', 'num_outbound_cmds']]\n",
    "\n",
    "train_df = pd.read_csv(f'dataset/nsl-kdd/KDDTrain+.txt', header=None)\n",
    "test_df = pd.read_csv(f'dataset/nsl-kdd/KDDTest+.txt', header=None)\n",
    "\n",
    "train_df = Dataset(train_df, columns).get_label5()\n",
    "test_df = Dataset(test_df, columns).get_label5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding of categorical variables\n",
    "- One-Hot Encoding converts categorical variables into binary vectors where each category is represented by a column, and a value of 1 indicates the presence of that category. While this method is effective for non-ordinal features, it can lead to a significant increase in the number of features, especially for high-cardinality variables (for instance, the feature \"service\" has 70 possible values)\n",
    "- Label Encoding assigns an integer to each category in a categorical variable. Each unique category is mapped to a specific number, making it more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0         0        491          0     0               0       0    0   \n",
       "1         0        146          0     0               0       0    0   \n",
       "2         0          0          0     0               0       0    0   \n",
       "3         0        232       8153     0               0       0    0   \n",
       "4         0        199        420     0               0       0    0   \n",
       "\n",
       "   num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_RSTO  \\\n",
       "0                  0          0                0  ...       0.0        0.0   \n",
       "1                  0          0                0  ...       0.0        0.0   \n",
       "2                  0          0                0  ...       0.0        0.0   \n",
       "3                  0          1                0  ...       0.0        0.0   \n",
       "4                  0          1                0  ...       0.0        0.0   \n",
       "\n",
       "   flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
       "0          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "1          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "2          0.0        0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "3          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "4          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "\n",
       "   flag_SH  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def oh_encoder(train_df, test_df, nominal_features):\n",
    "    enc = OneHotEncoder()\n",
    "    train_encoded = enc.fit_transform(train_df[nominal_features]).toarray()\n",
    "    test_encoded = enc.transform(test_df[nominal_features]).toarray()\n",
    "    new_columns = []\n",
    "    for i, feature in enumerate(nominal_features):\n",
    "        new_columns.extend([f\"{feature}_{str(cat)}\" for cat in enc.categories_[i]])\n",
    "\n",
    "    train_ohe = train_df.drop(nominal_features, axis=1)\n",
    "    train_ohe = pd.concat([train_ohe, pd.DataFrame(train_encoded, columns=new_columns)], axis=1)\n",
    "\n",
    "    test_ohe = test_df.drop(nominal_features, axis=1)\n",
    "    test_ohe = pd.concat([test_ohe, pd.DataFrame(test_encoded, columns=new_columns)], axis=1)\n",
    "\n",
    "    return train_ohe, test_ohe\n",
    "\n",
    "def l_encoder(train_df, test_df, nominal_features):\n",
    "    enc = LabelEncoder()\n",
    "    for feature in nominal_features:\n",
    "        train_df[feature] = enc.fit_transform(train_df[feature])\n",
    "        test_df[feature] = enc.transform(test_df[feature])\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "train_new, test_new = oh_encoder(train_df, test_df, ['protocol_type', 'service', 'flag'])\n",
    "train_new.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.558064e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.057999e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.681203e-07</td>\n",
       "      <td>6.223962e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.442067e-07</td>\n",
       "      <td>3.206260e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration     src_bytes     dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0       0.0  3.558064e-07  0.000000e+00     0             0.0     0.0  0.0   \n",
       "1       0.0  1.057999e-07  0.000000e+00     0             0.0     0.0  0.0   \n",
       "2       0.0  0.000000e+00  0.000000e+00     0             0.0     0.0  0.0   \n",
       "3       0.0  1.681203e-07  6.223962e-06     0             0.0     0.0  0.0   \n",
       "4       0.0  1.442067e-07  3.206260e-07     0             0.0     0.0  0.0   \n",
       "\n",
       "   num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_RSTO  \\\n",
       "0                0.0          0              0.0  ...       0.0        0.0   \n",
       "1                0.0          0              0.0  ...       0.0        0.0   \n",
       "2                0.0          0              0.0  ...       0.0        0.0   \n",
       "3                0.0          1              0.0  ...       0.0        0.0   \n",
       "4                0.0          1              0.0  ...       0.0        0.0   \n",
       "\n",
       "   flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
       "0          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "1          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "2          0.0        0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "3          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "4          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "\n",
       "   flag_SH  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train = train_new.copy()\n",
    "scaled_test = test_new.copy()\n",
    "scaled_train[numeric_features] = scaler.fit_transform(train_new[numeric_features])\n",
    "scaled_test[numeric_features] = scaler.transform(test_new[numeric_features])\n",
    "\n",
    "scaled_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection \n",
    "Several feature extraction methods have been tried"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectKBest is a selection routine of Scikit-learn that selects the top k features based on statistical tests. Various scoring functions \n",
    "- Mutual Information (mutual\\_info\\_classif): estimate mutual information for a discrete target variable, capturing non-linear relationships\n",
    "- Chi-Square (chi2): compute chi-squared stats between each non-negative feature and class\n",
    "- ANOVA F-Value (f\\_classif): compute the ANOVA F-value for the provided sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['hot', 'logged_in', 'root_shell', 'is_guest_login', 'count',\n",
      "       'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
      "       'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate',\n",
      "       'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
      "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
      "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
      "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
      "       'dst_host_srv_rerror_rate', 'protocol_type_icmp', 'protocol_type_tcp',\n",
      "       'service_eco_i', 'service_http', 'service_private', 'flag_RSTR',\n",
      "       'flag_S0', 'flag_SF'],\n",
      "      dtype='object')\n",
      "(125973, 30)\n",
      "Index(['logged_in', 'root_shell', 'is_guest_login', 'count', 'serror_rate',\n",
      "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
      "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_srv_count',\n",
      "       'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
      "       'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
      "       'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
      "       'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n",
      "       'protocol_type_icmp', 'service_domain_u', 'service_eco_i',\n",
      "       'service_ftp', 'service_ftp_data', 'service_http', 'service_private',\n",
      "       'flag_RSTR', 'flag_S0', 'flag_SF'],\n",
      "      dtype='object')\n",
      "(125973, 30)\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'logged_in', 'count', 'srv_count',\n",
      "       'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
      "       'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate',\n",
      "       'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
      "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
      "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
      "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
      "       'dst_host_srv_rerror_rate', 'protocol_type_tcp', 'service_domain_u',\n",
      "       'service_eco_i', 'service_http', 'service_private', 'flag_S0',\n",
      "       'flag_SF'],\n",
      "      dtype='object')\n",
      "(125973, 30)\n"
     ]
    }
   ],
   "source": [
    "def get_best_features(train_data, test_data, score_func, k):\n",
    "    X = train_data.drop(['label'], axis=1)\n",
    "    y = train_data['label']\n",
    "    selector = SelectKBest(score_func=score_func, k = k).fit(X, y)\n",
    "    X_train_selected = selector.transform(X)\n",
    "    X_test_selected = selector.transform(test_data.drop(['label'], axis=1))\n",
    "    selected_features = X.columns[selector.get_support()]\n",
    "    print(selected_features)\n",
    "    return X_train_selected, X_test_selected\n",
    "\n",
    "k = 30\n",
    "train_reduced, test_reduced = get_best_features(scaled_train, scaled_test, f_classif, k)\n",
    "print(train_reduced.shape)\n",
    "train_reduced, test_reduced = get_best_features(scaled_train, scaled_test, chi2, k)\n",
    "print(train_reduced.shape)\n",
    "train_reduced, test_reduced = get_best_features(scaled_train, scaled_test, mutual_info_classif, k)\n",
    "print(train_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation-based Feature Selection (CFS) selects features based on how well they correlate with the target variable while minimizing redundancy among the features. It aims to find a subset that is both highly relevant and uncorrelated with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfs(train_data, test_data):\n",
    "    X_train = train_data.drop(['label'], axis=1)\n",
    "    X_test = test_data.drop(['label'], axis=1)\n",
    "    corr_matrix = X_train.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "    X_train = X_train.drop(to_drop, axis=1)\n",
    "    X_test = X_test.drop(to_drop, axis=1)\n",
    "    print(X_train.columns)\n",
    "    return X_train, X_test\n",
    "\n",
    "k = 30\n",
    "train_reduced, test_reduced = cfs(scaled_train, scaled_test)\n",
    "print(train_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Recursive Feature Elimination (RFE), first an estimator is trained on the initial set of features. Then, the least important feature (or features, if a step>1 is used) is pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['protocol_type', 'service', 'flag', 'count', 'same_srv_rate',\n",
      "       'diff_srv_rate', 'dst_host_srv_count', 'dst_host_diff_srv_rate',\n",
      "       'dst_host_same_src_port_rate', 'dst_host_serror_rate'],\n",
      "      dtype='object')\n",
      "(125973, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def rfe(train_data, test_data, k):\n",
    "    X = train_data.drop(['label'], axis=1)\n",
    "    y = train_data['label']\n",
    "    X_test = test_data.drop(['label'], axis=1)\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    rfe = RFE(model, \n",
    "              n_features_to_select=k).fit(X, y)\n",
    "    X_train_selected = rfe.transform(X)\n",
    "    X_test_selected = rfe.transform(X_test)\n",
    "    print(X.columns[rfe.get_support()])\n",
    "    return X_train_selected, X_test_selected\n",
    "k = 10\n",
    "train_reduced, test_reduced = rfe(scaled_train, scaled_test, k)\n",
    "print(train_reduced.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential Feature Selection (SFS) is another iterative method that either adds (forward selection) or removes (backward selection) features based on the modelâ€™s performance. It builds up the feature set step-by-step to find the combination that maximizes a cross-validated score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
      "       'dst_bytes', 'wrong_fragment', 'hot', 'logged_in', 'num_compromised',\n",
      "       'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
      "       'num_shells', 'num_access_files', 'is_host_login', 'is_guest_login',\n",
      "       'srv_count', 'rerror_rate', 'srv_rerror_rate', 'diff_srv_rate',\n",
      "       'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
      "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
      "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
      "       'dst_host_rerror_rate'],\n",
      "      dtype='object')\n",
      "(125973, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def sfs(train_data, test_data, k):\n",
    "    X = train_data.drop(['label'], axis=1)\n",
    "    y = train_data['label']\n",
    "    X_test = test_data.drop(['label'], axis=1)\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    sfs = SequentialFeatureSelector(model, \n",
    "                                    cv = StratifiedKFold(n_splits=5, random_state=123, shuffle=True),\n",
    "                                    scoring = 'accuracy', \n",
    "                                    direction='forward', \n",
    "                                    n_features_to_select=k).fit(X, y)\n",
    "    X_train_selected = sfs.transform(X)\n",
    "    X_test_selected = sfs.transform(X_test)\n",
    "    print(X.columns[sfs.get_support()])\n",
    "    return X_train_selected, X_test_selected\n",
    "\n",
    "train_reduced, test_reduced = sfs(scaled_train, scaled_test, k)\n",
    "print(train_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a dimensionality reduction technique that transforms features into a smaller set of uncorrelated components, retaining the variance of the original data. While it doesnâ€™t directly select features, PCA is useful for reducing noise and computational complexity, especially in high-dimensional datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 10)\n",
      "[[ 1.97239503e-04  8.74210130e-07  4.01557696e-07 ... -3.28222212e-05\n",
      "  -3.29683995e-01  1.63419185e-03]\n",
      " [ 1.54281505e-02  5.11690574e-05  3.97206242e-05 ... -1.61307442e-04\n",
      "  -1.64290313e-01 -4.21078364e-04]\n",
      " [ 1.73229208e-03 -1.61375042e-05 -6.04738304e-06 ... -3.56023482e-04\n",
      "   1.88934025e-01  1.03135283e-03]\n",
      " ...\n",
      " [ 4.03490360e-02  8.88548644e-05  1.10158497e-04 ...  6.45131001e-04\n",
      "  -4.25828878e-02  1.41110399e-02]\n",
      " [-1.28611309e-02 -1.68730407e-04 -4.13224447e-05 ... -1.25405259e-03\n",
      "   7.63766085e-02 -3.70843352e-03]\n",
      " [ 1.01648253e-01  9.47433680e-05  2.88094806e-04 ...  1.42498069e-03\n",
      "  -1.85103583e-01  2.21159493e-02]]\n",
      "[0.41252402 0.15651982 0.10942724 0.05073837 0.04106383 0.02822428\n",
      " 0.02268929 0.01979969 0.01497984 0.01378681]\n",
      "[1.74893431 0.66358048 0.46392705 0.21511009 0.17409395 0.11965947\n",
      " 0.09619337 0.08394264 0.06350844 0.05845049]\n",
      "[469.37911462 289.12378026 241.74742763 164.61423976 148.09106357\n",
      " 122.77517341 110.08029591 102.83201099  89.44431379  85.80865064]\n",
      "1823.8960705686402\n",
      "(125973, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca(train_data, test_data, k):\n",
    "    X = train_data.drop(['label'], axis=1)\n",
    "    X_test = test_data.drop(['label'], axis=1)\n",
    "\n",
    "    pca = PCA(n_components=k)\n",
    "    X_train_pca = pca.fit_transform(X)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    print(X_train_pca.shape)\n",
    "    print(pca.components_)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    print(pca.explained_variance_)\n",
    "    print(pca.singular_values_)\n",
    "    print(pca.singular_values_.sum())\n",
    "\n",
    "    return X_train_pca, X_test_pca\n",
    "\n",
    "k = 10\n",
    "train_reduced, test_reduced = pca(scaled_train, scaled_test, k)\n",
    "print(train_reduced.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envTesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
